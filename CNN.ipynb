{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4eb4cae-f41f-45ab-a184-59f1e7518f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import sklearn\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b281b-682e-46e1-b195-cbc670f7811f",
   "metadata": {},
   "source": [
    "## Testing on the Pistacio_Image_Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deb58bc-5d24-476d-93c5-2fb08b800c11",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "82ca8bd7-7afe-409f-9739-08738b05d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, transforms=None):\n",
    "        \n",
    "        base_dir = os.path.dirname(os.path.abspath(__name__))\n",
    "        image_dir = os.path.join(\"Pistachio_Image_Dataset\", \"Pistachio_Image_Dataset\")\n",
    "        \n",
    "        class_translation = {0: \"Kirmizi\", 1: \"siirt\"}\n",
    "        class_dir_names = {0: \"Kirmizi_Pistachio\", 1: \"Siirt_Pistachio\"}\n",
    "        \n",
    "        kirmizi_abs_files = [os.path.join(image_dir, class_dir_names[0], file) for file in os.listdir(os.path.join(image_dir, class_dir_names[0]))]\n",
    "        siirt_abs_files = [os.path.join(image_dir, class_dir_names[1], file) for file in os.listdir(os.path.join(image_dir, class_dir_names[1]))]\n",
    "\n",
    "        self.image_files = kirmizi_abs_files + siirt_abs_files\n",
    "        self.classes = np.full(len(kirmizi_abs_files), 0).tolist() + np.full(len(siirt_abs_files), 1).tolist()\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.classes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.image_files[idx]\n",
    "        img_class = self.classes[idx]\n",
    "        \n",
    "        image = cv2.imread(img_path)\n",
    "        sample = {\"image\": image, \"class\": img_class}\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            smaple = self.transforms(sample)\n",
    "\n",
    "        return sample\n",
    "        \n",
    "ds = CustomDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78195935-e7fa-4230-abe3-3e980248b791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2148"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b4d65285-93b6-4dd9-83a3-845a61c16e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8),\n",
       " 'class': 0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba413a5e-0212-403f-9dcb-0f658e9b93ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training",
   "language": "python",
   "name": "training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
