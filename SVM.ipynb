{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1547c480-6c9a-4da0-a4c3-2ab83390baf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import hdbscan\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchsummary\n",
    "import torch.optim as optim\n",
    "import wandb \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe5bd28-f982-4755-bc4a-8fe2c804b18e",
   "metadata": {},
   "source": [
    "# Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d96792-36f9-40d7-8dec-3d20316905a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"train.pk\")\n",
    "val = pd.read_pickle(\"val.pk\")\n",
    "test = pd.read_pickle(\"test.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33b944eb-6fe8-4a0b-a150-394be6a55815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[\"BookingCode\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "973347ec-a724-4a87-abb8-a0d6f30f69ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ds = pd.concat([train, val, test])\n",
    "\n",
    "label_dict = {i:  booking_code for i, booking_code in enumerate(full_ds[\"BookingCode\"].unique().tolist())}\n",
    "booking_code_to_label = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "# PartNumber\n",
    "part_number_dict = {i:  part_number for i, part_number in enumerate(full_ds[\"PartNumber\"].unique().tolist())}\n",
    "part_number_to_label = {v: k for k, v in part_number_dict.items()}\n",
    "\n",
    "# hdbscanCluster\n",
    "cluster_dict = {i:  cluster_number for i, cluster_number in enumerate(full_ds[\"hdbscanCluster\"].unique().tolist())}\n",
    "cluster_to_label = {v: k for k, v in cluster_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a23fa85-3da0-4239-a6ff-83dc39f348d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, preprocess_transforms=None):\n",
    "        self.raw_data = dataframe\n",
    "        self.preprocess_transforms = preprocess_transforms\n",
    "        self.part_num_classes = len(part_number_dict)\n",
    "        self.cluster_classes = len(cluster_dict)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        row = self.raw_data.iloc[idx]\n",
    "\n",
    "        text_emb = np.array(row[\"descriptionEmbeddings\"])\n",
    "        part_num_idx = part_number_to_label[row[\"PartNumber\"]]\n",
    "        price_norm = row[\"NormPrice\"]\n",
    "        cluster_idx = cluster_to_label[row[\"hdbscanCluster\"]]\n",
    "\n",
    "        # One-hot encode part_num and cluster\n",
    "        part_num_one_hot = np.zeros(self.part_num_classes)\n",
    "        part_num_one_hot[part_num_idx] = 1\n",
    "\n",
    "        cluster_one_hot = np.zeros(self.cluster_classes)\n",
    "        cluster_one_hot[cluster_idx] = 1\n",
    "\n",
    "        vector = np.concatenate([text_emb, part_num_one_hot, [price_norm], cluster_one_hot])\n",
    "\n",
    "        label = booking_code_to_label[row[\"BookingCode\"]]\n",
    "\n",
    "        sample = {\n",
    "            \"vector\": vector,\n",
    "            \"label\": label\n",
    "        }\n",
    "\n",
    "        # Apply preprocessing transforms if provided\n",
    "        if self.preprocess_transforms is not None:\n",
    "            sample = self.preprocess_transforms(sample)\n",
    "\n",
    "        return sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "181498ff-6800-4223-9fc8-85d3f3b3da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CustomDataset(train)\n",
    "val_ds = CustomDataset(val)\n",
    "test_ds = CustomDataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bfbf292-55ae-4e51-9ede-2773cba21a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_numpy(dataset):\n",
    "    \"\"\"\n",
    "    Convert a PyTorch Dataset into NumPy arrays for vectors and labels.\n",
    "    \n",
    "    Args:\n",
    "        dataset (Dataset): The dataset to convert.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - vectors: A 2D NumPy array where each row is a feature vector.\n",
    "            - labels: A list of corresponding labels.\n",
    "    \"\"\"\n",
    "    vectors = []\n",
    "    labels = []\n",
    "\n",
    "    for sample in dataset:\n",
    "        vectors.append(sample[\"vector\"])\n",
    "        labels.append(sample[\"label\"])\n",
    "\n",
    "    # Stack vectors into a single NumPy array\n",
    "    vectors = np.stack(vectors)\n",
    "\n",
    "    return vectors, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96c24da7-cc6b-44ee-9a9f-daba2bd32c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_arr, train_labels = dataset_to_numpy(train_ds)\n",
    "val_ds_arr, val_labels = dataset_to_numpy(val_ds)\n",
    "test_ds_arr, test_labels = dataset_to_numpy(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e95123ee-31b1-4c2f-8535-f60e5b1ef3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'PartNumber', 'Description', 'Count', 'SumPrice', 'BookingCode',\n",
       "       'DocumentId', 'descriptionEmbeddings', 'Price', 'NormPrice',\n",
       "       'hdbscanCluster'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360a2bce-35d1-46bf-a037-afef5772a737",
   "metadata": {},
   "source": [
    "# Training the SVM One-VS-REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907c908c-71a7-4eda-9aed-1a6a7d22aeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)\n",
    "val_labels = label_encoder.transform(val_labels)\n",
    "test_labels = label_encoder.transform(test_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training",
   "language": "python",
   "name": "training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
